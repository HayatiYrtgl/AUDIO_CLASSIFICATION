# -*- coding: utf-8 -*-
"""audio_processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o13vQPq6r46WuoqUmDDBdmEZeseRqThF
"""



from google.colab import drive
drive.mount('/content/drive')

#cd drive/MyDrive

#! cp kaggle.json ~/.kaggle/

#! chmod 600 ~/.kaggle/kaggle.json

#!kaggle datasets download -d kenjee/z-by-hp-unlocked-challenge-3-signal-processing

#!unzip z-by-hp-unlocked-challenge-3-signal-processing.zip

"""# Kodlama Kısmı"""

import tensorflow as tf
import matplotlib.pyplot as plt

!pip install tensorflow_io

import tensorflow_io as tfio

"""# LOAD WAV FİLE"""

def load_wav_16k_mono(filename):

  file_contents = tf.io.read_file(filename)
  wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)
  wav = tf.squeeze(wav, axis=-1)
  sample_rate = tf.cast(sample_rate, dtype=tf.int64)
  wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)
  return wav

capuchine = "/content/drive/MyDrive/Parsed_Capuchinbird_Clips/XC114131-0.wav"
cap_wave = load_wav_16k_mono(capuchine)

"""# Wave shape"""

plt.plot(cap_wave)
plt.plot()

"""# Spektogram"""

# dataseti hazırlama
# yolları tanımlama
pos_data = "/content/drive/MyDrive/Parsed_Capuchinbird_Clips"
neg_data = "/content/drive/MyDrive/Parsed_Not_Capuchinbird_Clips"

pos = tf.data.Dataset.list_files(pos_data+"/*.wav")
neg = tf.data.Dataset.list_files(neg_data+"/*.wav")

pos.as_numpy_iterator().next()

# label ekleme
positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))
negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))
data = positives.concatenate(negatives)

"""#CALCULATING WAVE CYCLE LENGTH"""

import os
lengths = []
for file in os.listdir("/content/drive/MyDrive/Parsed_Capuchinbird_Clips") :
  print(file)
  tensor_wave = load_wav_16k_mono("/content/drive/MyDrive/Parsed_Capuchinbird_Clips/"+file)
  lengths.append(len(tensor_wave))

"""# Calculate Mean,Min,Max"""

tf.math.reduce_mean(lengths)

# numpy kısmı/ 16k mono
average = 54156/16000
average

tf.math.reduce_min(lengths)

tf.math.reduce_max(lengths)

# minumum 32000 max 80000 ortalama olarak 64000 veya 48000 seçilebilir

"""# Preprocessin function"""

def preprocess(file_path, label):
  wav = load_wav_16k_mono(file_path)
  wav = wav[:48000]
  zero_padding = tf.zeros([48000]-tf.shape(wav),dtype=tf.float32)
  wav = tf.concat([zero_padding, wav], 0)
  spectogram = tf.signal.stft(wav, frame_length=320, frame_step=32)
  spectogram = tf.abs(spectogram)
  spectogram = tf.expand_dims(spectogram, axis=2)
  return spectogram, label

# rastgele olanı göster
filepath, label = positives.shuffle(buffer_size=1000).as_numpy_iterator().next()
spectogram, label = preprocess(filepath, label)
plt.figure(figsize=(30,20))
plt.imshow(tf.transpose(spectogram)[0])
plt.show()

"""# BUİLD DEEP LEARNİNG MODEL

# Create training and testing partitions
"""

# data pipeline
data = data.map(preprocess)
data = data.cache()
data = data.shuffle(buffer_size=1000)
data = data.batch(16)
data = data.prefetch(8)

# split into train test
# toplam verinin %70 i train olacak
print(len(data))
len(data)*0.7

# 36 veri traine geri kalanı teste gidecek yani 15
train = data.take(36)
test = data.skip(36).take(15)

# bi sample şekline bakalım
samples, labels = train.as_numpy_iterator().next()
samples.shape

# 1491, 247, 1 input shape i

"""# DERİN ÖĞRENME MODELİ"""

from keras import Sequential
from keras.layers import Conv2D, Dense, Flatten, MaxPool2D
model = Sequential()
model.add(Conv2D(16, kernel_size=(3,3), activation="relu", input_shape=(1491,257,1)))
model.add(MaxPool2D(pool_size=(4,4), strides=(2,2)))
model.add(Conv2D(16, kernel_size=(3,3), activation="relu"))
model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))
model.add(Flatten())
model.add(Dense(128, activation="relu"))
model.add(Dense(1, activation="sigmoid"))
model.summary()

from keras.metrics import *
model.compile(optimizer="Adam", loss="binary_crossentropy", metrics=["accuracy", Recall(), Precision()], run_eagerly=True)

train

# fit
hist = model.fit(train, epochs=4, validation_data=test, batch_size=32)

# plotting
import pandas as pd
df = pd.DataFrame(hist.history).plot(title="metrics", xlabel="epochs", ylabel="values")
df.get_figure().savefig("/content/drive/MyDrive/audio_metrics.png")

# save model
model.save("/content/drive/MyDrive/capuchine.h5")

# prediction kısmı

X_test, y_test = test.as_numpy_iterator().next()

X_test.shape

y_test.shape

"""# daha sonra modeli kullanmak  istersen yine preprocess işlemi yapmak zorundasın yani 16k monoya dönüştürüp, tekrardan spectograma çevirmen lazım"""

y_hat = model.predict(X_test)

#  convert logits to classes
y_predictions = [1 if prediction > 0.5 else 0 for prediction in y_hat]

y_predictions

#compare results
pred = tf.math.reduce_sum(y_predictions)
real = tf.math.reduce_sum(y_test)
print(pred, real)

"""# classify audioclip"""

def load_mp3_16k_mono(filename):

  res = tfio.audio.AudioIOTensor(filename)
  tensor = res.to_tensor()
  tensor = tf.math.reduce_sum(tensor, axis=1) / 2
  sample_rate = res.rate
  sample_rate = tf.cast(sample_rate, dtype=tf.int64)
  # resample
  wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)
  return wav

# forest audio
mp3 = "/content/drive/MyDrive/Forest_Recordings/recording_00.mp3"

wav = load_mp3_16k_mono(mp3)

# ğpreprocess mp3
def preprocess_mp3(sample, index):
  sample = sample[0]
  zero_padding= tf.zeros([48000]-tf.shape(sample), dtype=tf.float32)
  wav = tf.concat([zero_padding, sample], 0)
  spectogram = tf.signal.stft(wav, frame_length=320, frame_step=32)
  spectogram = tf.abs(spectogram)
  spectogram = tf.expand_dims(spectogram, axis=2)
  return spectogram

# audio slices
audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav,sequence_length=48000, sequence_stride=48000, batch_size=1)

# longer clips
audio_slices = audio_slices.map(preprocess_mp3)
audio_slices = audio_slices.batch(64)

y_prediction_long = model.predict(audio_slices)
y_predictions_long = [1 if prediction > 0.9 else 0 for prediction in y_prediction_long]

len(y_predictions_long)

from itertools import groupby
yhat = [key for key, group in groupby(y_predictions_long)]

tf.math.reduce_sum(yhat)

"""# Bunu fonksiyon  haline getirip sonuçlara bakabilirsin"""